{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UK Data Science Job Analysis\n",
    "\n",
    "## Objective\n",
    "\n",
    "To analyse data scraped from Indeed.co.uk for jobs matching the query \"Data Scientist\". Aiming to answer these 5 questions:\n",
    "\n",
    "1. Which are the most requested skills/technologies for a Data Scientist position?\n",
    "2. What kind of salary/day rate can be expected?\n",
    "3. Do roles tend to be permanent or contract/temporary roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from markdownify import markdownify\n",
    "import re\n",
    "import math\n",
    "import requests\n",
    "import bs4\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    " def scrape_indeed_job_ids(query):\n",
    "    \"\"\"\n",
    "    Run a job search query on the Indeed.co.uk website and for returning results.\n",
    "    \n",
    "    Iterate through the paginated results (50 at a time which was found to be the maximum) building an array of unique job_id to be returned.\n",
    "    \n",
    "    The job ids can be used in later calls to gather job details such as job title, expected salary, skills etc.\n",
    "\n",
    "    args:\n",
    "        query: the search query for jobs that you wish to run e.g. \"Data Scientist\"\n",
    "\n",
    "    returns:\n",
    "        array of str which are the job_ids\n",
    "    \"\"\"\n",
    "    \n",
    "    query = query.replace(' ','+')\n",
    "    \n",
    "    pc_re = re.compile('\\s+Page (?P<current_job_no>\\d+) of (?P<job_count>\\d+) jobs')\n",
    "\n",
    "    job_ids = []\n",
    "    \n",
    "    page = 0\n",
    "    page_count = 1\n",
    "\n",
    "    while page < page_count:\n",
    "        if page == 0:\n",
    "            resp = requests.get(f'https://www.indeed.co.uk/jobs?q={query}&limit=50')\n",
    "            bs = bs4.BeautifulSoup(resp.text, 'html.parser')\n",
    "            result = pc_re.match(bs.select('#searchCountPages')[0].text)\n",
    "            \n",
    "            if result:\n",
    "                job_count = result.group('job_count')\n",
    "                page_count = math.ceil(int(job_count)/50)\n",
    "        else:\n",
    "            resp = requests.get(f'https://www.indeed.co.uk/jobs?q=data+scientist&limit=50&start={page*50}')\n",
    "            bs = bs4.BeautifulSoup(resp.text, 'html.parser')\n",
    "        \n",
    "        job_ids += [div['id'][div['id'].find('_')+1:] for div in bs.select('div.row.result')]\n",
    "        \n",
    "        page+=1\n",
    "\n",
    "    return list(set(job_ids))\n",
    "\n",
    "def scrape_indeed_job_details(job_id):\n",
    "    \"\"\"\n",
    "    For the given job_id scrape the specific job details using the first json call.\n",
    "    \n",
    "    Next request the full page for the job_id to enable scraping of the job description plain text and html\n",
    "    \"\"\"\n",
    "    resp = requests.get(f'https://www.indeed.co.uk/viewjob?jk={job_id}&from=vjs&vjs=1')\n",
    "    \n",
    "    job_json = resp.json()\n",
    "\n",
    "    job = {}\n",
    "\n",
    "    job['job_id'] = job_id\n",
    "    job['json'] = str(job_json)\n",
    "    job['title'] = job_json['jobTitle']\n",
    "    job['hiring_organization'] = job_json['sicm']['cmN']\n",
    "    job['location'] = job_json['jobLocation']\n",
    "    try:\n",
    "        job['salary_expectation_average'] = job_json['sEx']['sAvg']\n",
    "    except:\n",
    "        job['salary_expectation_average'] = None\n",
    "\n",
    "    try:\n",
    "        job['salary_expectation_range'] = job_json['sEx']['sRg']\n",
    "    except:\n",
    "        job['salary_expectation_range'] = None\n",
    "        \n",
    "    try:\n",
    "        job['salary_expectation_per'] = job_json['sEx']['sT']\n",
    "    except:\n",
    "        job['salary_expectation_per'] = None        \n",
    "        \n",
    "    try:\n",
    "        job['job_type'] = job_json['jts']\n",
    "    except:\n",
    "        job['job_type'] = None\n",
    "        \n",
    "    try:\n",
    "        job['skills_de'] = job_json['dem']['de']\n",
    "    except:\n",
    "        job['skills_de'] = None\n",
    "        \n",
    "    resp = requests.get(f'https://www.indeed.co.uk/viewjob?jk={job_id}')\n",
    "    \n",
    "    bs = bs4.BeautifulSoup(resp.text, 'html.parser')\n",
    "    div = bs.find(\"div\", {\"id\": \"jobDescriptionText\"})\n",
    "    job['job_description_html'] = div.encode_contents()\n",
    "    job['job_description'] = div.text\n",
    "        \n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 432/819 [02:46<02:28,  2.60it/s]"
     ]
    }
   ],
   "source": [
    "job_details = []\n",
    "\n",
    "job_ids = scrape_indeed_job_ids('Data Scientist')\n",
    "\n",
    "for i in trange(len(job_ids)):\n",
    "    job_details.append(scrape_indeed_job_details(job_ids[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
